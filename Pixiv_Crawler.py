import re
import os
import os.path as op
import sys
import json
import colorama
from colorama import init,Fore,Back,Style
from New_api import *
from Downloader import *

init(autoreset=True)

class Pixiv(object):
    def __init__(self):
        self.root = sys.path[0]
        self.cache_path = "{}\\cache\\".format(self.root)
        if not op.exists(self.cache_path):
            os.makedirs(self.cache_path)

        self.User_Info = self.Load_List("User_Info")
        if not self.User_Info:
            self.User_Info = {"User_Name": "", "Password": "", "Collect_Progress": 0, "Download_Path": ""}
        self.USER_ID = ""
        self.USER_NAME = ""      
        self.api = New_api()
        self.Log_in()
            
    def Log_in(self):
        while not self.User_Info["User_Name"]:
            self.User_Info["User_Name"] = input("è¯·è¾“å…¥ç”¨æˆ·åï¼š")
        while not self.User_Info["Password"]:    
            self.User_Info["Password"] = input("è¯·è¾“å…¥å¯†ç ï¼š")
        self.api.require_appapi_hosts()
        self.api.set_accept_language('zh-CN')
        Login_Messgae = self.api.login(self.User_Info["User_Name"], self.User_Info["Password"]).response
        self.USER_ID = Login_Messgae.user.id
        self.USER_NAME = Login_Messgae.user.name
        print("Welcome Back {}".format(self.USER_NAME))
        
    #ä»æœ¬åœ°è¯»å–jsonæ–‡ä»¶
    def Load_List(self, File_Name):
        path = "{}{}_cache.json".format(self.cache_path, File_Name)
        if op.isfile(path):
            try:
                with open(path, 'r') as Cache_File:
                    L = json.load(Cache_File)
            except:
                # ç¼“å­˜æ–‡ä»¶æ ¼å¼å‡ºç°é—®é¢˜ï¼Œåˆ é™¤ç¼“å­˜æ–‡ä»¶
                os.remove(path)
                return []
            else:              
                return L
        else:
            return []
         
    #ä¿å­˜æŒ‡å®šå˜é‡åˆ°jsonæ–‡ä»¶
    def Save_List(self, File_Name, Target_List):
        with open("{}{}_cache.json".format(self.cache_path, File_Name), 'w') as Cache_File:      
            json.dump(Target_List, Cache_File)
        
    def Get_Follow_List(self):  
        # å¦‚æœå­˜åœ¨ç¼“å­˜æ–‡ä»¶ï¼Œåˆ™ä»æœ¬åœ°è¯»å–è¯¥ç”¨æˆ·çš„å…³æ³¨åˆ—è¡¨
        Follow_List = self.Load_List("{}_Follow_List".format(self.USER_NAME))
        # å‘Apiè¯·æ±‚å…³æ³¨äººæ•°
        Total_Follow = self.api.user_detail(self.USER_ID).profile.total_follow_users
        # å¦‚æœå…³æ³¨äººæ•°æœªå¢åŠ ï¼Œä¸æŠ“å–æ–°åˆ—è¡¨
        if Total_Follow == len(Follow_List):
            print("æˆåŠŸä»ç¼“å­˜ä¸­è¿›è¡ŒåŠ è½½, ä½ å…³æ³¨äº† {} åä½œè€…ã€‚\n".format(len(Follow_List)))
            return
        elif op.isfile("{}{}_Follow_List_cache.json".format(self.cache_path, self.USER_NAME)):
                os.remove("{}{}_Follow_List_cache.json".format(self.cache_path, self.USER_NAME))
        Follow_List = []
        # å‘Apiè¯·æ±‚å…³æ³¨æ¸…å•
        json_result = self.api.user_following(self.USER_ID)
        while True:
            for users in json_result.user_previews:
                ID = users.user.id
                Name = self.Filter_Name(users.user.name)
                if not self.Find_Follow_ID(Follow_List, ID):
                    Follow_List.append([ID, Name])
            self.Save_List("{}_Follow_List".format(self.USER_NAME), Follow_List)
            print("å·²å…³æ³¨çš„ä½œè€…åˆ—è¡¨æ­£åœ¨æ”¶é›†ä¸­, è¿›åº¦ï¼š{}/{}".format(len(Follow_List),Total_Follow))
            # å¦‚æœå½“å‰é¡µé¢ä¸ºæœ€åä¸€é¡µåˆ™é€€å‡ºå¾ªç¯
            if not json_result.next_url:
                break
            # è¯·æ±‚æ¸…å•ä¸‹ä¸€é¡µ
            json_result = self.api.next_page_f(json_result.next_url)

        print("å·²å…³æ³¨çš„ä½œè€…åˆ—è¡¨æ”¶é›†å®Œæˆ, ä½ å…³æ³¨äº† {} åä½œè€…ã€‚\n".format(len(Follow_List))) 
            
    def Find_Follow_ID(self, List, ID):
        for i in range(len(List)):
            if List[i][0] == ID:
                return i+1
        return False
            
    def Get_Follow_Illust_List(self):
        Follow_List = self.Load_List("{}_Follow_List".format(self.USER_NAME))
        if not Follow_List:
            print("è¯·å…ˆè·å–å…³æ³¨åˆ—è¡¨")
            return

        n = len(Follow_List) - self.User_Info["Collect_Progress"]
        for Artist in Follow_List[self.User_Info["Collect_Progress"]:]:                  
            self.Get_Illust_List(Artist[0])
            self.User_Info["Collect_Progress"] += 1
            self.Save_List("User_Info", self.User_Info)
            n -= 1
            if n%10 == 0:
                print("å‰©ä½™ {} ä¸ªä½œè€…\n".format(n))
        self.User_Info["Collect_Progress"] = 0
        self.Save_List("User_Info", self.User_Info)

    def Get_Illust_List(self, Artist_ID):
        # åˆ©ç”¨ç”¨æˆ·IDå‘Apiè¯·æ±‚ä½œè€…çš„ä¿¡æ¯
        Artist_Detail = self.api.user_detail(Artist_ID)
        try:
            Name = self.Filter_Name(Artist_Detail.user.name)
        except:
            return
        Total_Illusts = Artist_Detail.profile.total_illusts

        Catch_Name = "{}({})_Illust_List".format(Artist_ID, Name)
        Illust_List = self.Load_List(Catch_Name)
        # å¦‚æœå‘ç°æ–°ä½œå“åˆ™é‡æ–°è·å–ä¸€æ¬¡ä½œå“åˆ—è¡¨
        if Total_Illusts == len(Illust_List) - 2:
            print("æˆåŠŸä»ç¼“å­˜ä¸­åŠ è½½ä½œè€… \033[32m{}\033[0m çš„ä½œå“åˆ—è¡¨ï¼Œå…±æœ‰ \033[33m{}\033[0m å‰¯ä½œå“ã€‚\n".format(Name, Total_Illusts))
            return
        Illust_List = [Artist_ID, Name]

        # åˆ©ç”¨ç”¨æˆ·IDå‘Apiè¯·æ±‚ä½œå“åˆ—è¡¨
        json_result = self.api.user_illusts(Artist_ID)       
        while True:
            for Illust_Info in json_result.illusts:            
                Illust_ID = str(Illust_Info.id)   
                if not self.Find_Illust_ID(Illust_List[2:], Illust_ID):
                    Title = re.sub(r'[^a-zA-Z0-9\u4e00-\u9fa5]+-,\'()',' ',Illust_Info.title)
                    Title = re.sub(r'[(].{1,}[)]',' ',Title)
                    Illust_Dict = {"ID": Illust_ID, "Title": Title,"Illust_Date": ''.join(list(filter(str.isdigit, Illust_Info.create_date)))[:8], 
                                    "Image_Urls": Illust_Info.meta_single_page if Illust_Info.page_count == 1 else Illust_Info.meta_pages, 
                                    "Tags": Illust_Info.tags, "Page_Count": Illust_Info.page_count, "is_block": False}
                    Illust_Dict = self.Filter(Illust_Dict)
                    Illust_List.append(Illust_Dict)
            self.Save_List(Catch_Name, Illust_List)
            print("ä½œè€… \033[32m{}\033[0m çš„ä½œå“ä¿¡æ¯æ­£åœ¨æ”¶é›†ä¸­, è¿›åº¦ï¼š\033[33m{}/{}\033[0m".format(Name,len(Illust_List) - 2, Total_Illusts))
            if not json_result.next_url:
                break
            # è¯·æ±‚æ¸…å•ä¸‹ä¸€é¡µ
            json_result = self.api.next_page_i(json_result.next_url)              
                    
        print("ä½œè€… \033[32m{}\033[0m çš„å…¨éƒ¨ä½œå“æ”¶é›†å®Œæˆï¼Œå…±æœ‰ \033[33m{}\033[0m å‰¯ä½œå“ã€‚\n".format(Name, Total_Illusts))
            
    def Find_Illust_ID(self, Illust_List, Illust_ID):
        for Illust in Illust_List:
            if Illust['ID'] == Illust_ID:
                return True
        return False

    def Filter(self, Illust_Dict):
        Tag = Illust_Dict["Tags"]
        for i in range(len(Tag)):
            if Tag[i]["translated_name"] is not None:
                Tag[i] = Tag[i]["translated_name"]
            else:
                Tag[i] = Tag[i]["name"]


        if int(Illust_Dict["ID"]) < 20180101:
            Illust_Dict["is_block"] = True
        else:
            Black_List = ["LINE stickers", "sticker", "creator's stickers", "manga", "comic", "summer Comiket", "ç»ƒä¹ ", 
                      "å†¬CM", "è‰å›¾", "åˆ€å‰‘ä¹±èˆ", "è®²åº§", "æŠ±æ•", "notification", "å››æ ¼æ¼«ç”»"]
            for Keyword in Black_List:
                if Tag.count(Keyword):
                    # åŒ…å«é»‘åå•ä¸­tagçš„å›¾ç‰‡ç›´æ¥æ’é™¤
                    Illust_Dict["is_block"] = True
        return Illust_Dict

    def Filter_Name(self, Name):
        Name = re.sub(r'[^a-zA-Z0-9\u4e00-\u9fa5]+-,\'()',"",Name)
        Name = re.sub(r'[@ï¼ /ğŸ”â– â—†].{1,}',"",Name)
        Name = re.sub(r'[Cc][0-9]{2,3}.{1,}',"",Name)
        return Name

def main():
    crawler = Pixiv()
    download = Downloader(crawler.User_Info["Download_Path"])
    # ç”¨æˆ·ç•Œé¢
    while True:        
        print("åŠŸèƒ½ï¼š\n\t1. æ”¶é›†ä¸ªäººå…³æ³¨åˆ—è¡¨\n\t2. æ”¶é›†æŒ‡å®šä½œè€…çš„ä½œå“åˆ—è¡¨\n\t3. æ”¶é›†å…¨éƒ¨å·²å…³æ³¨ç”»å¸ˆçš„ä½œå“åˆ—è¡¨")
        print("\t4. ä¸‹è½½å•ä¸ªä½œå“\n\t5. ä¸‹è½½æŒ‡å®šä½œè€…çš„ä½œå“\n\t6. ä¸‹è½½å…¨éƒ¨å·²å…³æ³¨ç”»å¸ˆçš„ä½œå“ï¼ˆæœªå®Œå·¥ï¼‰")
        print("\t7. è®¾ç½®\n\t8. é€€å‡ºç¨‹åº")
        order = "5"
        order = input("è¯·è¾“å…¥æŒ‡ä»¤ï¼ˆ1-8ï¼‰ï¼š")


        if order == "1":
            crawler.Get_Follow_List()
            print("æ”¶é›†å®Œæˆï¼Œç¼“å­˜æ–‡ä»¶ä½äº{}\\cache\\æ–‡ä»¶å¤¹ä¸‹ï¼Œè¯·ä¸è¦åˆ é™¤ã€‚".format(crawler.root))

        elif order == "2":
            ID = input("è¯·è¾“å…¥ä½œè€…IDï¼š")
            if int(ID) <= 0 :
                print("ä½œè€…IDä¸æ­£ç¡®")
                continue
            crawler.Get_Illust_List(ID)
            print("æ”¶é›†å®Œæˆï¼Œç¼“å­˜æ–‡ä»¶ä½äº{}\\cache\\æ–‡ä»¶å¤¹ä¸‹ï¼Œè¯·ä¸è¦åˆ é™¤ã€‚".format(crawler.root))

        elif order == "3":
            crawler.Get_Follow_Illust_List()
            print("æ”¶é›†å®Œæˆï¼Œç¼“å­˜æ–‡ä»¶ä½äº{}\\cache\\æ–‡ä»¶å¤¹ä¸‹ï¼Œè¯·ä¸è¦åˆ é™¤ã€‚".format(crawler.root))

        elif order == "4":
            Pic_ID = input("è¯·è¾“å…¥ä½œå“IDï¼š")
            if int(Pic_ID) <= 0 :
                print("ä½œå“IDä¸æ­£ç¡®")
                continue
            Pic_Detail = crawler.api.illust_detail(Pic_ID).illust
            Title = crawler.Filter_Name(Pic_Detail.title)
            Sub_Title = Pic_Detail.image_urls["large"][-3:]
            name = "({}){}.{}".format(Pic_ID, Title, Sub_Title)
            if Pic_Detail.page_count > 1:
                url = Pic_Detail.meta_pages
                download.Pic_Download(url, name, s = True)
            else:
                url = Pic_Detail.meta_single_page
                download.Pic_Download(url, name)

        elif order == "5":
            ID = "50258193"
            ID = input("è¯·è¾“å…¥ä½œè€…IDï¼š")
            if int(ID) <= 0 :
                print("ä½œè€…IDä¸æ­£ç¡®")
                continue
            crawler.Get_Illust_List(ID)
            download.Artist_Download(ID)

#        elif order == "6":

        elif order == "7":
            while True:
                print("1. ç™»é™†é‚®ç®±\n2. å¯†ç \n3. ä¸‹è½½è·¯å¾„\n4. é€€å‡º")
                order = input("è¯·è¾“å…¥æŒ‡ä»¤ï¼ˆ1-4ï¼‰ï¼š")
                if order == "1":
                    crawler.User_Info["User_Name"] = input("è¯·è¾“å…¥ï¼š\n")
                elif  order == "2":
                    crawler.User_Info["Password"] = input("è¯·è¾“å…¥ï¼š\n")
                elif  order == "3":
                    print("å½“å‰ä¸‹è½½è·¯å¾„ä¸ºï¼š {}".format(crawler.User_Info["Download_Path"]))
                    Path = input("è¯·è¾“å…¥ï¼š\n")
                    crawler.User_Info["Download_Path"] =  Path + "\\"
                    download.Set_Path(Path)
                    print("å½“å‰ä¸‹è½½è·¯å¾„ä¸ºï¼š {}".format(crawler.User_Info["Download_Path"]))
                elif  order == "4":
                    break

        elif order == "8":
            crawler.Save_List("User_Info", crawler.User_Info)
            break
        os.system('cls')

if __name__ == '__main__':
    main()